{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d375a955-0669-4323-912a-9a511df4290f"
      },
      "source": [
        "# ë¨¸ì‹ ëŸ¬ë‹ ëŒë¦¬ê¸° (ê¸°ë³¸)\n",
        "### history-stations\n",
        "- ìƒˆë¡œìš´ ë³€ìˆ˜ ì¶”ê°€, íŠœë‹ ë“± ì§„í–‰í•˜ì§€ ì•ŠìŒ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "id": "B13NnVmFQl8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„"
      ],
      "metadata": {
        "id": "TO3exh77t3vo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab8fc94d-d480-44d1-a34e-c407dc92af4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from prophet import Prophet\n",
        "import holidays\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë°©ë¬¸ììˆ˜ ë°ì´í„° ë°ì´í„° í”„ë ˆì„ ë³€í™˜"
      ],
      "metadata": {
        "id": "cNPDRsKQt8xJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93f9d138-4e6f-48a9-9883-52cb7f7dad47"
      },
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "client = MongoClient('ì£¼ì†Œ ì‘ì„±')\n",
        "\n",
        "db = client.crawling\n",
        "\n",
        "collection = db['ì£¼ì†Œ ì‘ì„±']\n",
        "\n",
        "rows = collection.find()\n",
        "history_stations = []\n",
        "for row in rows:\n",
        "    history_stations.append(row)\n",
        "\n",
        "history_stations = pd.DataFrame(history_stations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ RandomForestRegressor"
      ],
      "metadata": {
        "id": "yr40leIKuBSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd481307-2c2b-4e04-b773-f6befc67e004"
      },
      "outputs": [],
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(random_state=0)\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # print(pre_df)\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "    # print(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ad2d5b8-9f5e-4832-a9f1-a80bf790a098"
      },
      "source": [
        "- 5/23ì— ìƒˆë¡œ ìƒê²¨ë‚œ ì¶©ì „ì†Œì— ëŒ€í•´ì„œ ë°ì´í„°ê°€ ì—†ì–´ì„œ ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŒ => ì‹œê°„ ê²½ê³¼ ìë™ í•´ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a988697-21ce-4246-af83-97e9ea6b4e60"
      },
      "source": [
        "- blue = test, orange = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b5c3b40-d5ef-46a7-9389-97c163daa6fe",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "5H-0AGjAlaym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "NUV3QOFUe1hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "oxrl72eIb1S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ LinearRegression"
      ],
      "metadata": {
        "id": "PqUSM-o_z__P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km2JqXFwz__P"
      },
      "outputs": [],
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = LinearRegression()\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrOxpeXIz__Q"
      },
      "source": [
        "- 5/23ì— ìƒˆë¡œ ìƒê²¨ë‚œ ì¶©ì „ì†Œì— ëŒ€í•´ì„œ ë°ì´í„°ê°€ ì—†ì–´ì„œ ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŒ => ì‹œê°„ ê²½ê³¼ ìë™ í•´ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbBjFqTdz__Q"
      },
      "source": [
        "- blue = test, orange = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DNdo4_m2z__Q"
      },
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "nGVWXsRpz__R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "eoboHGzVz__R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "KDYu3x2Wz__R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ LGBMRegressor"
      ],
      "metadata": {
        "id": "BYiAjhZh1LZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maJN01OU1LZc"
      },
      "outputs": [],
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = LGBMRegressor(random_state=0, verbose=-1)\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APqb3nFN1LZc"
      },
      "source": [
        "- 5/23ì— ìƒˆë¡œ ìƒê²¨ë‚œ ì¶©ì „ì†Œì— ëŒ€í•´ì„œ ë°ì´í„°ê°€ ì—†ì–´ì„œ ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŒ => ì‹œê°„ ê²½ê³¼ ìë™ í•´ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1s2i6Lv1LZc"
      },
      "source": [
        "- blue = test, orange = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VHFosV3F1LZc"
      },
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "RBFJuYnr1LZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "F58D3V3W1LZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "Ci6L5LIQ1LZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ xgboost"
      ],
      "metadata": {
        "id": "fEWb3uKQs6p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = xgb.XGBRegressor(\n",
        "        eval_metric='rmse'  # íšŒê·€ì—ì„œëŠ” r2ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
        "    )\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "gOcWTW-_tXZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ],
      "metadata": {
        "id": "Hq_B4o8guuq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "UxOy-dmsuTYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "_3pDvvyquTYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "G91XtrHYuTYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFesEBBk-mqH"
      },
      "source": [
        "# ë¨¸ì‹ ëŸ¬ë‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ â­\n",
        "(ì´ˆê¸° 0.65)\n",
        "## í‰ê°€ ê¸°ì¤€ r2(ê²°ì •ê³„ìˆ˜)\n",
        "## 1. RandomForestRegressor ğŸ‘ğŸ‘\n",
        "## ê²°ê³¼: 0.7486\n",
        "## 2. LinearRegression\n",
        "## ê²°ê³¼: 0.2363\n",
        "## 3. LGBMRegressor\n",
        "## ê²°ê³¼: 0.7023\n",
        "## 4. xgboost\n",
        "## ê²°ê³¼: 0.6801"
      ]
    }
  ]
}