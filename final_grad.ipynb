{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d375a955-0669-4323-912a-9a511df4290f"
      },
      "source": [
        "# ë¨¸ì‹ ëŸ¬ë‹ ëŒë¦¬ê¸° (ê¸°ë³¸)\n",
        "### history-stations\n",
        "- ìƒˆë¡œìš´ ë³€ìˆ˜ ì¶”ê°€, íŠœë‹ ë“± ì§„í–‰í•˜ì§€ ì•ŠìŒ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "id": "B13NnVmFQl8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„"
      ],
      "metadata": {
        "id": "TO3exh77t3vo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab8fc94d-d480-44d1-a34e-c407dc92af4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from prophet import Prophet\n",
        "import holidays\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "now = datetime.now()\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### config íŒŒì¼ ì—…ë¡œë“œ"
      ],
      "metadata": {
        "id": "APQNtd1t24aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# íŒŒì¼ ì—…ë¡œë“œ\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "2tRlfzl33HgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### config.txt íŒŒì¼ì—ì„œ MongoDB ì •ë³´ ê°€ì ¸ì˜¤ê¸°"
      ],
      "metadata": {
        "id": "5yqkAytk2PR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config.txt íŒŒì¼ì—ì„œ MongoDB ì •ë³´ ì½ê¸°\n",
        "config = {}\n",
        "\n",
        "# config.txt íŒŒì¼ì„ ì½ì–´ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
        "with open('config.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        # ì¤„ì—ì„œ ê³µë°±ì„ ì œê±°í•˜ê³  '=' ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‚¤-ê°’ í˜•íƒœë¡œ ì €ì¥\n",
        "        key, value = line.strip().split('=')\n",
        "        config[key] = value\n",
        "\n",
        "# config.txtì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´ë¡œ MongoDB ì—°ê²°\n",
        "mongo_uri = config.get('MONGO_URI')\n",
        "db_pw = int(config.get('PW'))\n",
        "collection_name = config.get('COLLECTION_NAME')"
      ],
      "metadata": {
        "id": "NBA9vra32Vme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë°©ë¬¸ììˆ˜ ë°ì´í„° ë°ì´í„° í”„ë ˆì„ ë³€í™˜"
      ],
      "metadata": {
        "id": "cNPDRsKQt8xJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93f9d138-4e6f-48a9-9883-52cb7f7dad47"
      },
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# ë°ì´í„°ê°€ ì €ì¥ëœ MongoDBì˜ ì£¼ì†Œ\n",
        "client = MongoClient(mongo_uri, db_pw)\n",
        "\n",
        "# dbë¥¼ ì €ì¥í•˜ê¸°\n",
        "db = client.crawling\n",
        "\n",
        "collection = db[collection_name]\n",
        "\n",
        "# collectionì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ ë° ì €ì¥\n",
        "rows = collection.find()\n",
        "history_stations = []\n",
        "for row in rows:\n",
        "    history_stations.append(row)\n",
        "\n",
        "history_stations = pd.DataFrame(history_stations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ RandomForestRegressor"
      ],
      "metadata": {
        "id": "yr40leIKuBSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd481307-2c2b-4e04-b773-f6befc67e004"
      },
      "outputs": [],
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(random_state=0)\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # print(pre_df)\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "    # print(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ad2d5b8-9f5e-4832-a9f1-a80bf790a098"
      },
      "source": [
        "- 5/23ì— ìƒˆë¡œ ìƒê²¨ë‚œ ì¶©ì „ì†Œì— ëŒ€í•´ì„œ ë°ì´í„°ê°€ ì—†ì–´ì„œ ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŒ => ì‹œê°„ ê²½ê³¼ ìë™ í•´ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a988697-21ce-4246-af83-97e9ea6b4e60"
      },
      "source": [
        "- blue = test, orange = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b5c3b40-d5ef-46a7-9389-97c163daa6fe",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "5H-0AGjAlaym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "NUV3QOFUe1hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "oxrl72eIb1S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ LinearRegression"
      ],
      "metadata": {
        "id": "PqUSM-o_z__P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km2JqXFwz__P"
      },
      "outputs": [],
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = LinearRegression()\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrOxpeXIz__Q"
      },
      "source": [
        "- 5/23ì— ìƒˆë¡œ ìƒê²¨ë‚œ ì¶©ì „ì†Œì— ëŒ€í•´ì„œ ë°ì´í„°ê°€ ì—†ì–´ì„œ ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŒ => ì‹œê°„ ê²½ê³¼ ìë™ í•´ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbBjFqTdz__Q"
      },
      "source": [
        "- blue = test, orange = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DNdo4_m2z__Q"
      },
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "nGVWXsRpz__R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "eoboHGzVz__R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "KDYu3x2Wz__R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ LGBMRegressor"
      ],
      "metadata": {
        "id": "BYiAjhZh1LZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maJN01OU1LZc"
      },
      "outputs": [],
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = LGBMRegressor(random_state=0, verbose=-1)\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APqb3nFN1LZc"
      },
      "source": [
        "- 5/23ì— ìƒˆë¡œ ìƒê²¨ë‚œ ì¶©ì „ì†Œì— ëŒ€í•´ì„œ ë°ì´í„°ê°€ ì—†ì–´ì„œ ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŒ => ì‹œê°„ ê²½ê³¼ ìë™ í•´ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1s2i6Lv1LZc"
      },
      "source": [
        "- blue = test, orange = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VHFosV3F1LZc"
      },
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "RBFJuYnr1LZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "F58D3V3W1LZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "Ci6L5LIQ1LZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ xgboost"
      ],
      "metadata": {
        "id": "fEWb3uKQs6p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i]) # history_chargersì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "\n",
        "    model = xgb.XGBRegressor(\n",
        "        eval_metric='rmse'  # íšŒê·€ì—ì„œëŠ” r2ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
        "    )\n",
        "\n",
        "    model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "    y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "    y_pred = np.round(y_pred)\n",
        "\n",
        "    print(history_stations['_id'][i], end=' ')\n",
        "    print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "    acc = model.score(x_test, y_test)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "    y_pred = pd.DataFrame(y_pred)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "    y_test.reset_index(inplace=True)\n",
        "    df = pd.concat([y_test, y_pred], axis=1)\n",
        "    df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "    # # ì‹œê°í™”\n",
        "    # plt.figure(figsize=(8,6))\n",
        "    # sns.lineplot(x='time' , y='y_test', data=df)\n",
        "    # sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "    # plt.xticks(rotation=50)\n",
        "    # plt.show()\n",
        "\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "gOcWTW-_tXZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ],
      "metadata": {
        "id": "Hq_B4o8guuq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²°ì •ê³„ìˆ˜ r2 ê°’ì´ 0.7ì´ìƒì´ë©´ ì¢‹ì€ ëª¨ë¸, 0.3 ì´ìƒì´ë©´ í‰ë²”í•œ ëª¨ë¸ë¡œ í‰ê°€"
      ],
      "metadata": {
        "id": "UxOy-dmsuTYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NaN ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "has_none_or_nan = any(x is None or (isinstance(x, float) and np.isnan(x)) for x in arr)\n",
        "print(has_none_or_nan) # nanê°’ì´ ìˆìœ¼ë©´ True\n",
        "\n",
        "## NaN ê°’ì´ ìˆëŠ” í–‰ í™•ì¸\n",
        "indices_with_none_or_nan = [i for i, x in enumerate(arr) if x is None or (isinstance(x, float) and np.isnan(x))]\n",
        "print(indices_with_none_or_nan)\n",
        "\n",
        "## NaN ê°’ ì œê±°\n",
        "filtered_list = [x for x in arr if x is not None and not (isinstance(x, float) and np.isnan(x))]\n",
        "print(filtered_list)"
      ],
      "metadata": {
        "id": "_3pDvvyquTYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(arr))\n",
        "print(max(arr))\n",
        "print(len(arr))\n",
        "print(sum(filtered_list) / len(filtered_list))\n",
        "# arr.index(0.9711363007518797)"
      ],
      "metadata": {
        "id": "G91XtrHYuTYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXX4FLv33A6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFesEBBk-mqH"
      },
      "source": [
        "# ë¨¸ì‹ ëŸ¬ë‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ â­\n",
        "(ì´ˆê¸° 0.65)\n",
        "## í‰ê°€ ê¸°ì¤€ r2(ê²°ì •ê³„ìˆ˜)\n",
        "## 1. RandomForestRegressor ğŸ‘ğŸ‘\n",
        "## ê²°ê³¼: 0.7486\n",
        "## 2. LinearRegression\n",
        "## ê²°ê³¼: 0.2363\n",
        "## 3. LGBMRegressor\n",
        "## ê²°ê³¼: 0.7023\n",
        "## 4. xgboost\n",
        "## ê²°ê³¼: 0.6801"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë”¥ëŸ¬ë‹ ëŒë¦¬ê¸°(ê¸°ë³¸)"
      ],
      "metadata": {
        "id": "ARiSaIDNv5SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë”¥ëŸ¬ë‹ ì½”ë“œ LSTM"
      ],
      "metadata": {
        "id": "d4kmAX-ayAZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ml(i):\n",
        "    df_h = pd.DataFrame(history_stations['history'][i])  # history_stationsì˜ ië²ˆì§¸ history ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "    df_h['weekday'] = df_h['time'].dt.weekday\n",
        "    df_h['month'] = df_h['time'].dt.month\n",
        "    df_h['day'] = df_h['time'].dt.day\n",
        "    df_h['hour'] = df_h['time'].dt.hour\n",
        "    df_h['minute'] = df_h['time'].dt.minute\n",
        "\n",
        "    # ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "    kr_holidays = holidays.KR()\n",
        "    df_h['holiday'] = df_h.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "    df_h.set_index(keys='time', inplace=True)\n",
        "\n",
        "    # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "    count = df_h.iloc[0, 0]\n",
        "\n",
        "    # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "    target = 'visitNum'\n",
        "\n",
        "    # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "    x = df_h.drop(target, axis=1)\n",
        "    y = df_h[target]\n",
        "\n",
        "    # ë°ì´í„° ìƒ˜í”Œ ìˆ˜ í™•ì¸ (10ê°œ ì´í•˜ì¸ ê²½ìš° ì˜ˆì¸¡ ìƒëµ)\n",
        "    if len(df_h) <= 10:\n",
        "        return 0\n",
        "    else:\n",
        "        # ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ì‹œê³„ì—´ êµì°¨ ê²€ì¦ (TimeSeriesSplit)\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "        for train_index, test_index in tscv.split(x):\n",
        "            x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
        "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # LSTM ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° í˜•ìƒ ë³€í™˜\n",
        "        def create_lstm_data(x, y, time_step=1):\n",
        "            X, y_lstm = [], []\n",
        "            for i in range(len(x) - time_step):\n",
        "                X.append(x.iloc[i:(i + time_step)].values)\n",
        "                y_lstm.append(y.iloc[i + time_step])\n",
        "            return np.array(X), np.array(y_lstm)\n",
        "\n",
        "        time_step = 1  # ì˜ˆë¥¼ ë“¤ì–´, 1ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ì˜ˆì¸¡\n",
        "        X_train, y_train_lstm = create_lstm_data(x_train, y_train, time_step)\n",
        "        X_test, y_test_lstm = create_lstm_data(x_test, y_test, time_step)\n",
        "\n",
        "        # LSTM ëª¨ë¸ ì •ì˜\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(0.2))  # Dropout ë ˆì´ì–´ ì¶”ê°€ (ê³¼ì í•© ë°©ì§€)\n",
        "        model.add(LSTM(units=50, return_sequences=False))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(units=1))  # ì˜ˆì¸¡í•˜ë ¤ëŠ” ê°’ì€ 1ê°œ (visitNum)\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "        # LSTM ëª¨ë¸ í•™ìŠµ\n",
        "        model.fit(X_train, y_train_lstm, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred = np.round(y_pred)\n",
        "\n",
        "        print(history_stations['_id'][i], end=' ')\n",
        "        print(r2_score(y_test_lstm, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "        acc = model.evaluate(X_test, y_test_lstm, verbose=0)\n",
        "\n",
        "        # ì‹œê°í™”ë¥¼ ìœ„í•œ DataFrame ìƒì„±\n",
        "        y_pred_df = pd.DataFrame(y_pred)\n",
        "        y_test_df = pd.DataFrame(y_test_lstm)\n",
        "\n",
        "        # í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°\n",
        "        y_test_df.reset_index(inplace=True)\n",
        "        df = pd.concat([y_test_df, y_pred_df], axis=1)\n",
        "        df.columns = ['time', 'y_test', 'y_pred']\n",
        "\n",
        "        # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ DataFrame ìƒì„±\n",
        "        pre_df = pd.date_range(now.date() + timedelta(days=1), periods=24, freq=\"30min\")  # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "        pre_df = pd.DataFrame(pre_df)\n",
        "        pre_df.columns = ['time']  # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "        pre_df['count'] = count\n",
        "\n",
        "        # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "        pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "        pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "        pre_df['month'] = pre_df['time'].dt.month\n",
        "        pre_df['day'] = pre_df['time'].dt.day\n",
        "        pre_df['hour'] = pre_df['time'].dt.hour\n",
        "        pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "        kr_holidays = holidays.KR()\n",
        "        pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "        pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "        # LSTMì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡\n",
        "        pre_X, _ = create_lstm_data(pre_df, pd.Series(np.zeros(len(pre_df))), time_step)\n",
        "        pre_predict = model.predict(pre_X)\n",
        "        pre_predict = np.round(pre_predict)\n",
        "\n",
        "        pre_predict = pre_predict.tolist()\n",
        "        collection = db['demand-info']\n",
        "\n",
        "        statId = history_stations['_id'][i]\n",
        "        # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "        existing_doc = collection.find_one({\"statId\": statId})\n",
        "\n",
        "        # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "        if existing_doc is None:\n",
        "            new_doc = {\"statId\": statId, \"demandInfo\": {\"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": []}}\n",
        "            result = collection.insert_one(new_doc)\n",
        "            print(\"Added new document\")\n",
        "\n",
        "        collection.update_one(\n",
        "            {\"statId\": statId},\n",
        "            {\"$set\": {'demandInfo.hourlyVisitNum': pre_predict}}\n",
        "        )\n",
        "\n",
        "        return acc"
      ],
      "metadata": {
        "id": "q1LxIi4ByEaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range(len(history_stations)):\n",
        "    arr.append(run_ml(i))\n",
        "print(np.mean(arr))"
      ],
      "metadata": {
        "id": "YelM-c4myYAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ëª¨ë“  ì¶©ì „ì†Œ ì •ë³´ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° => df_all"
      ],
      "metadata": {
        "id": "734bxHC3AtLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# history_stationsì˜ ê° í•­ëª©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥\n",
        "dfs = []\n",
        "\n",
        "# ì²« ë²ˆì§¸ í•­ëª© ì²˜ë¦¬\n",
        "for i in range(len(history_stations)):\n",
        "    df_temp = pd.DataFrame(history_stations['history'][i])  # history í•­ëª©ì„ DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "    df_temp['_id'] = history_stations['_id'][i]  # _id ê°’ì„ ì¶”ê°€\n",
        "    dfs.append(df_temp)  # ê° DataFrameì„ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "\n",
        "# ëª¨ë“  DataFrameì„ í•œ ë²ˆì— concat\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# ê²°ê³¼ í™•ì¸\n",
        "df_all.tail()"
      ],
      "metadata": {
        "id": "H9uRWEubBf32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ì„ì˜ì˜ ë‚ ì§œ ë³€ìˆ˜ ì¶”ê°€"
      ],
      "metadata": {
        "id": "nYhYiSPlDywX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë³€ìˆ˜ ìƒì„± (ì£¼ë§, ì›”, ì¼, ì‹œê°„, ë¶„) #########################\n",
        "df_all['weekday'] = df_all['time'].dt.weekday\n",
        "df_all['month'] = df_all['time'].dt.month\n",
        "df_all['day'] = df_all['time'].dt.day\n",
        "df_all['hour'] = df_all['time'].dt.hour\n",
        "df_all['minute'] = df_all['time'].dt.minute\n",
        "\n",
        "# ë³€ìˆ˜ ìƒì„± (ê³µíœ´ì¼)\n",
        "kr_holidays = holidays.KR()\n",
        "df_all['holiday'] = df_all.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "# ml ì‹¤í–‰ì„ ìœ„í•´ ë‚ ì§œë¥¼ indexë¡œ ì„¤ì •í•˜ê¸°\n",
        "df_all.set_index(keys='time', inplace=True)"
      ],
      "metadata": {
        "id": "V_9hVDJSD_Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_all['_id'].value_counts())"
      ],
      "metadata": {
        "id": "geadbbpgEIn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ì¶©ì „ì†Œ _id ê°’ì„ ì¸ì½”ë”©í•˜ê¸°\n",
        "- id ê°’ì´ ê³ ìœ í•œ ì¹´í…Œê³ ë¦¬ì¸ë°, Label Encodingì€ ìˆ«ì ìˆœì„œê°€ í¬ê¸°ë¥¼ ì•”ë¬µì ìœ¼ë¡œ ë¶€ì—¬í•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ê·¸ ì‚¬ì´ì˜ ìˆ«ì ì°¨ì´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.\n",
        "- ì˜ˆë¥¼ ë“¤ì–´, id 0ê³¼ id 1ì´ ë‹¤ë¥¼ ë¿ì¸ë°, ëª¨ë¸ì€ ì´ ì°¨ì´ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ë‹¤ë¥´ê²Œ ì·¨ê¸‰í•  ìˆ˜ ìˆë‹¤.\n",
        "- id ê°’ì„ 0, 1, 2...ì™€ ê°™ì€ ì—°ì†ì ì¸ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ë©´, ëª¨ë¸ì´ ì´ ê°’ë“¤ ê°„ì˜ ìˆœì„œ ê´€ê³„ë‚˜ í¬ê¸° ì°¨ì´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ëŠ”ë°, ì´ëŠ” ì‹¤ì œë¡œ ì˜ë¯¸ê°€ ì—†ì„ ìˆ˜ ìˆë‹¤.\n",
        "- One Hot Encodingì€ ì¶©ì „ì†Œì˜ ìˆ˜ê°€ 2471 + Î±ì´ê¸° ë•Œë¬¸ì— ë³€ìˆ˜ê°€ ë„ˆë¬´ ë§ì´ ìƒê²¨ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.\n",
        "- ê·¸ëŸ¬ë¯€ê³  ê°€ì¥ ìœ ìš©í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” target_encodingì„ í™œìš©í•œë‹¤."
      ],
      "metadata": {
        "id": "H3VAJxGcEMe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### target encoding ì ìš©"
      ],
      "metadata": {
        "id": "DPO_Bnv_HJ6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ê° '_id'ì— ëŒ€í•´ target ê°’(visitNum)ì˜ í‰ê· ì„ êµ¬í•˜ê¸°\n",
        "target_means = df_all.groupby('_id')['visitNum'].mean()\n",
        "\n",
        "# 2. '_id' ì»¬ëŸ¼ì„ í•´ë‹¹ í‰ê·  ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê¸°\n",
        "df_all['id_encoded'] = df_all['_id'].map(target_means)\n",
        "\n",
        "# _id ì»¬ëŸ¼ ì‚­ì œí•˜ê¸°\n",
        "df_all = df_all.drop('_id', axis=1)"
      ],
      "metadata": {
        "id": "UPq8zBoNF8Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.head()"
      ],
      "metadata": {
        "id": "TimYWwXYGMHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "count = df_all.iloc[0, 0]\n",
        "\n",
        "# target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "target = 'visitNum'\n",
        "\n",
        "# x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "x = df_all.drop(target, axis=1)\n",
        "y = df_all[target]\n",
        "\n",
        "\n",
        "# ë°ì´í„°ê°€ 10ê°œ ì´ìƒì¼ ê²½ìš°, ê¸°ì¡´ì²˜ëŸ¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "model = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "\n",
        "model.fit(x_train, y_train) # ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "y_pred = model.predict(x_test) # ëª¨ë¸ ì˜ˆì¸¡\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "print(r2_score(y_test, y_pred))  # ëª¨ë¸ ì •í™•ë„ ì¶œë ¥\n",
        "acc = model.score(x_test, y_test)\n",
        "\n",
        "# ì‹œê°í™”ë¥¼ ìœ„í•¨ - df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "\n",
        "# í•˜ë‚˜ì˜ dfë¡œ í•©ì¹˜ê¸°\n",
        "y_test.reset_index(inplace=True)\n",
        "df = pd.concat([y_test, y_pred], axis=1)\n",
        "df.columns = ['time', 'y_test', 'y_pred']"
      ],
      "metadata": {
        "id": "ip6ZuwLsGUBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'y_test'ì™€ 'y_pred' ì—´ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ í‰ê°€\n",
        "\n",
        "# RÂ² (R-squared) í‰ê°€\n",
        "r2 = r2_score(df['y_test'], df['y_pred'])\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "\n",
        "# MSE (Mean Squared Error) í‰ê°€\n",
        "mse = mean_squared_error(df['y_test'], df['y_pred'])\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# RMSE (Root Mean Squared Error) í‰ê°€\n",
        "rmse = mse ** 0.5\n",
        "print(f\"Root Mean Squared Error: {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "0fnwpxFYLzKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(x='time' , y='y_test', data=df)\n",
        "sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "plt.xticks(rotation=50)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_XmHcamectWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¼ì • ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ìƒ˜í”Œë§ (ì˜ˆ: 2471ê°œë§ˆë‹¤ í•˜ë‚˜ì”© ì„ íƒ)\n",
        "df_resampled = df.iloc[::2471, :]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(x='time', y='y_test', data=df_resampled, label='Actual')\n",
        "sns.lineplot(x='time', y='y_pred', data=df_resampled, label='Predicted')\n",
        "plt.xticks(rotation=50)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6mgQOf9ngaTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### êµì°¨ ê²€ì¦ìœ¼ë¡œ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê³ , í•´ë‹¹ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•œ í›„ ì˜ˆì¸¡ê³¼ ì„±ëŠ¥ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ"
      ],
      "metadata": {
        "id": "oBtg6RHKHfyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # count ë³€ìˆ˜ ì €ì¥í•˜ê¸°\n",
        "# count = df_all.iloc[0, 0]\n",
        "\n",
        "# # target(ì˜ˆì¸¡í•  ì—´) ì„¤ì •í•˜ê¸°\n",
        "# target = 'visitNum'\n",
        "\n",
        "# # x, y ê°’ ì„¤ì •í•˜ê¸°\n",
        "# x = df_all.drop(target, axis=1)\n",
        "# y = df_all[target]\n",
        "\n",
        "# # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (ê¸°ì¡´ì²˜ëŸ¼)\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
        "\n",
        "# # ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ì´ˆê¸°í™”\n",
        "# model = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
        "\n",
        "# # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì • (êµì°¨ ê²€ì¦ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ë²”ìœ„)\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 200],    # íŠ¸ë¦¬ ê°œìˆ˜\n",
        "#     'max_depth': [10, 20, 30, None],    # íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´\n",
        "#     'min_samples_split': [2, 5, 10],    # ë¶„í• í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
        "#     'min_samples_leaf': [1, 2, 4],      # ë¦¬í”„ ë…¸ë“œì— í•„ìš”í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
        "#     'max_features': ['auto', 'sqrt', 'log2'],  # ê° íŠ¸ë¦¬ì—ì„œ ì„ íƒí•  íŠ¹ì„±ì˜ ìˆ˜\n",
        "# }\n",
        "\n",
        "# # GridSearchCV ì‚¬ìš©: êµì°¨ ê²€ì¦ì„ í†µí•´ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
        "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "\n",
        "# # GridSearchCVë¡œ í•™ìŠµ\n",
        "# grid_search.fit(x_train, y_train)\n",
        "\n",
        "# # ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
        "# print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# # ìµœì ì˜ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
        "# best_model = grid_search.best_estimator_\n",
        "\n",
        "# # ëª¨ë¸ ì˜ˆì¸¡\n",
        "# y_pred = best_model.predict(x_test)\n",
        "\n",
        "# # ì˜ˆì¸¡ ê²°ê³¼ ë°˜ì˜¬ë¦¼\n",
        "# y_pred = np.round(y_pred)\n",
        "\n",
        "# # ì •í™•ë„ ì¶œë ¥ (R2 score)\n",
        "# print(f\"R2 score: {r2_score(y_test, y_pred)}\")\n",
        "\n",
        "# # ëª¨ë¸ ì •í™•ë„ (score method)\n",
        "# acc = best_model.score(x_test, y_test)\n",
        "# print(f\"Model accuracy (R^2 score): {acc}\")\n",
        "\n",
        "# # ì‹œê°í™”ë¥¼ ìœ„í•œ df í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "# y_pred_df = pd.DataFrame(y_pred, columns=['y_pred'])\n",
        "# y_test_df = pd.DataFrame(y_test).reset_index(drop=True)\n",
        "\n",
        "# # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ í•©ì¹˜ê¸°\n",
        "# df = pd.concat([y_test_df, y_pred_df], axis=1)\n",
        "# df.columns = ['y_test', 'y_pred']\n",
        "\n",
        "# # ê²°ê³¼ ì¶œë ¥\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "4py2zA8gJjZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'y_test'ì™€ 'y_pred' ì—´ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ í‰ê°€\n",
        "\n",
        "# RÂ² (R-squared) í‰ê°€\n",
        "r2 = r2_score(df['y_test'], df['y_pred'])\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "\n",
        "# MSE (Mean Squared Error) í‰ê°€\n",
        "mse = mean_squared_error(df['y_test'], df['y_pred'])\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# RMSE (Root Mean Squared Error) í‰ê°€\n",
        "rmse = mse ** 0.5\n",
        "print(f\"Root Mean Squared Error: {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "2zPuQgxtMY_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(x='time' , y='y_test', data=df)\n",
        "sns.lineplot(x='time' , y='y_pred', data=df)\n",
        "plt.xticks(rotation=50)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lfpkON_1Wf9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ì‹¤ì œ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í›„ MongoDBì— ë°˜ì˜í•˜ê¸° ğŸŒŸ"
      ],
      "metadata": {
        "id": "Nq7-iYUvShXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ml(i):\n",
        "    # ì‹œê°„ ë‹¨ìœ„ë³„ ì˜ˆì¸¡ df ìƒì„±\n",
        "    pre_df = pd.date_range(now.date()+ timedelta(days=1) , periods=24 , freq=\"30min\") # 30ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ df ë§Œë“¤ê¸°\n",
        "\n",
        "    pre_df = pd.DataFrame(pre_df) # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜\n",
        "    pre_df.columns=['time'] # ì—´ ì´ë¦„ ë³€ê²½\n",
        "\n",
        "    id = history_stations['_id'][i]\n",
        "\n",
        "    pre_df['count'] = count\n",
        "\n",
        "    # ë³€ìˆ˜ ì¶”ê°€í•˜ê¸°\n",
        "    pre_df['time'] = pd.to_datetime(pre_df['time'])\n",
        "    pre_df['weekday'] = pre_df['time'].dt.weekday\n",
        "    pre_df['month'] = pre_df['time'].dt.month\n",
        "    pre_df['day'] = pre_df['time'].dt.day\n",
        "    pre_df['hour'] = pre_df['time'].dt.hour\n",
        "    pre_df['minute'] = pre_df['time'].dt.minute\n",
        "\n",
        "    kr_holidays = holidays.KR()\n",
        "    pre_df['holiday'] = pre_df.time.apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    pre_df.set_index(keys='time', inplace=True)\n",
        "\n",
        "    #### target encodingì„ ì‚¬ìš©í•˜ë ¤ê³  í•˜ëŠ”ë° ê°ê° targetì„ iê°’ ë³„ë¡œ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—\n",
        "    pre_df['id_encoded'] = target_means.iloc[i]\n",
        "\n",
        "\n",
        "    pre_predict = model.predict(pre_df)\n",
        "    pre_predict= np.round(pre_predict)\n",
        "\n",
        "    pre_predict = pre_predict.tolist()\n",
        "    collection = db['demand-info']\n",
        "\n",
        "    statId = history_stations['_id'][i]\n",
        "    # í•´ë‹¹ statIdë¥¼ ê°€ì§„ ë¬¸ì„œ ì¡°íšŒ\n",
        "\n",
        "    # print(id, statId)\n",
        "    # print(pre_predict)\n",
        "    existing_doc = collection.find_one({\"statId\": statId })\n",
        "\n",
        "    # ë¬¸ì„œê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ì—…ë°ì´íŠ¸\n",
        "    if existing_doc is None:\n",
        "        new_doc = { \"statId\": statId, \"demandInfo\": { \"viewNum\": 0, \"departsIn30m\": [], \"hourlyVisitNum\": [] } }\n",
        "        result = collection.insert_one(new_doc)\n",
        "        print(\"Added new document\")\n",
        "        #time.sleep(0.1)\n",
        "\n",
        "    x = collection.update_one(\n",
        "        {\"statId\":statId},\n",
        "        {\"$set\" : {\n",
        "            'demandInfo.hourlyVisitNum' : pre_predict\n",
        "        }\n",
        "        })"
      ],
      "metadata": {
        "id": "gZAzLUpoSnQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(history_stations)):\n",
        "    run_ml(i)"
      ],
      "metadata": {
        "id": "f7X_Wq3-Wx_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•©ì¹œ ë’¤ ì„±ëŠ¥\n",
        "- RandomForestRegressor : 0.9388\n",
        "- GridSearchCV êµì°¨ ê²€ì¦ì„ í†µí•´ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥í•œ RandomForestRegressor:"
      ],
      "metadata": {
        "id": "QFXAXMFqLgpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### k-meansë¡œ ìœ ì‚¬í•œ íŠ¹ì§•ì„ ê°€ì§„ ì¶©ì „ì†Œë“¤ë³„ë¡œ ëª¨ë¸ ë”°ë¡œ í•™ìŠµ ë° ì ìš©í•˜ê¸°"
      ],
      "metadata": {
        "id": "DwpmVXEnKZVX"
      }
    }
  ]
}